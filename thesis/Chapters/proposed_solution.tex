\chapter{Proposed Solution}

This chapter will discuss the methods this work considers to recognise the outer \(k\)-planar graphs. Besides recognition, these methods provide the outer \(k\)-planar drawings of the given graphs if possible. We represent the drawing as a sequence of vertices in the circular order they appear on the boundary of the outer face. Considering only straight-line drawings, this order uniquely determines all the edge crossings and, thus, also the number of crossings per edge.


\section{Bicomponent decomposition}

For complex problems, decomposing into smaller, independent subproblems often leads to a significant performance boost. In our context of recognising outer \(k\)-planar graphs, an effective strategy to do so is to partition the graph into subgraphs in such a manner that allows us to process them independently by the recognition algorithm. As the smallest part of the graph that can be processed by any algorithm independently of the remainder is a biconnected component, we use block-cut decomposition for this purpose, which splits the graph into biconnected components, referred to as blocks. It is worth noting that each graph edge belongs to a single block. However, any two bicomponents may share a vertex, referred to as a cut vertex. Considering blocks and cut vertices as graph nodes, we can construct a so-called block-cut tree, wherein a block node is connected to a cut node if and only if the corresponding biconnected component contains a corresponding vertex.

The advantage of this decomposition is that any method for recognising outer \(k\)-planar graphs can be applied separately to each component, and results can be combined easily afterwards. Specifically, if some component does not admit an outer \(k\)-planar drawing, neither does the whole graph. Otherwise, if all components admit such a drawing, they can be merged by combining duplicates of each cut vertex. This merging process does not introduce any additional edge crossings since both components are located on the outer face of each other. Moreover, as no new faces are created during this process -- due to the acyclic structure of the block-cut tree -- every vertex remains on the outer face of the graph during this process. Consequently, the resulting drawing of an original graph is outer \(k\)-planar, and it exists if and only if each biconnected component of the graph admits such a drawing.

In this work, we implemented this decomposition using the method \textsf{biconnected\_compo\-nents}\footnote{\url{https://www.boost.org/doc/libs/1_87_0/libs/graph/doc/biconnected_components.html}} from the Boost Graph Library~\cite{boost}. This function assigns an index of the bicomponent to each edge to which it belongs. Additionally, it provides a list of cut vertices. Afterwards, we copy each block as an independent graph and create mappings to translate new \emph{local} vertices back to their original identifiers. Finally, we construct a supergraph representing the structure of a block-cut tree wherein each node references a copied block along with corresponding mapping or a cut vertex.

To construct a final graph drawing, we perform a depth-first search on the block-cut tree, recording the predecessor for each node upon discovery. Also, each time a block vertex is discovered, we use one of the methods described in other sections of this chapter to check whether the component admits an outer \(k\)-planar drawing and obtain it if so. Afterwards, we merge the new drawing with the already existing one by combining the corresponding cut vertex as described before. If the considered block is the first encountered one, its drawing is directly copied into a sequence that will form the final drawing. Otherwise, the block necessarily has a predecessor. Due to the structure of a tree, it is a cut node corresponding to a vertex that is shared with some other block that has already been considered and thus added to a final drawing. As a result, we can find a corresponding cut vertex in both global and local drawings. Since each drawing is represented as a cyclic sequence of vertices, we can rotate the local drawing so that the corresponding cut vertex appears as the first item in a sequence. Finally, we insert the local drawing starting from the second element into the global one immediately after the cut vertex.

\section{ILP Formulation (unchanged)}\label{sec:ILP-def}

The result of the integral linear program should be an arrangement of vertices on a line.
Given the arrangement of the vertices, we can definitively identify whether two edges cross each other.
Indeed, consider two edges, $uv$ and $st$.
Without loss of generality, we can assume that $u$ is located before $v$ in the arrangement, $s$ before $t$, and $u$ before $s$.
Under these assumptions, the edges $uv$ and $st$ cross if and only if $s$ is located before $v$ and $t$ after $v$.

\todo[inline]{Image depicting 8 intersecting pairs out of 24 possibble}

The arrangement is represented using the so-called ``ordering variables''.
For every pair of vertices $u$ and $v$, we create a binary variable $a_{u, v}$ that defines the order in which they appear in the arrangement.
Equality $a_{u, v} = 1$ indicates that $u$ is located before $v$ and vice versa, and $a_{u, v} = 0$ indicates that $v$ is located before $u$ or $u$ and $v$ is the same vertex.

For these variables, it is crucial to ensure transitivity.
That is, if $a_{u, v} = 1$ and $a_{v, w} = 1$ which means $u$ is located before $v$ and $v$ is located before $w$, then $u$ must be located before $w$, so the following should hold $a_{u, w} = 1$.
This can be ensured by the following constraint: $a_{u, w} \geqslant a_{u, v} + a_{v, w} - 1$.
This constraint will restrict the value of $a_{u, w}$ if and only if both $a_{u, v}$ and $a_{v, w}$ equal $1$.
Otherwise, the constraint will have no impact on the system at all.

Having the arrangement of the vertices, we can now deduce for each pair of edges $uv$ and $st$ whether they intersect or not.
Naturally, there are 24 different arrangements of the vertices, as demonstrated in figure~\ref{fig:edge_crossings}.
Among them, there are only eight in which the edges intersect.
Thus, the edge $uv$ crosses the edge $st$ if and only if one of the following holds:
\begin{itemize}[noitemsep]
    \item $a_{u,s} = 1$, $a_{s,v} = 1$, and $a_{v,t} = 1$
    \item $a_{u,t} = 1$, $a_{t,v} = 1$, and $a_{v,s} = 1$
    \item $a_{v,s} = 1$, $a_{s,u} = 1$, and $a_{u,t} = 1$
    \item $a_{v,t} = 1$, $a_{t,u} = 1$, and $a_{u,s} = 1$
    \item $a_{s,u} = 1$, $a_{u,t} = 1$, and $a_{t,v} = 1$
    \item $a_{t,u} = 1$, $a_{u,s} = 1$, and $a_{s,v} = 1$
    \item $a_{s,v} = 1$, $a_{v,t} = 1$, and $a_{t,u} = 1$
    \item $a_{t,v} = 1$, $a_{v,s} = 1$, and $a_{s,u} = 1$
\end{itemize}

To describe this in the linear program, we create a binary variable $c_{uv, st}$ for every pair of edges $uv$ and $st$.
Equality $c_{uv, st} = 0$ indicates that the edge $uv$ does not cross $st$.
To ensure the correctness of these values, we impose eight constraints on each variable, one for each case from above.
For example, considering the case $a_{u,s} = 1$, $a_{s,v} = 1$, and $a_{v,t} = 1$, we impose the following restriction: $c_{uv, st} \geqslant a_{u,s} + a_{s,v} + a_{v,t} - 2$, which ensures that $c_{uv, st}$ equals $1$ whenever the vertices are ordered as $usvt$.
Making this for each case restricts $c_{uv, st}$ to the value $1$ if the vertices are arranged in one of the eight ``intersecting'' configurations, ensuring that $c_{uv, st} = 0$ is possible only if $uv$ does not cross $st$.

The algorithm's objective is to minimize the maximal number of crossings per edge.
This value can be written as follows: $\max_{uv \in E(G)} \sum_{st \in E(G)} c_{uv, st}$.
Unfortunately, it cannot represent an objective function for a linear program as the $\max$ operation is not linear.
To solve this, we introduce a new integer variable $k$.
To ensure that it is equal to the objective value, we impose the following constraint on $k$: $k \geqslant \sum_{st \in E(G)} c_{uv, st}$ for each edge $uv \in E(G)$.

So, the integer linear program can be described as follows:
\begin{align*}
    \textbf{minimize}\quad&k\\
    \textbf{subject to}\quad&&k &\geqslant \sum_{st \in E(G)} c_{uv, st},&&\forall uv \in E(G)\\
    &&c_{uv, st} &\geqslant a_{u,s} + a_{s,v} + a_{v,t} - 2,&&\forall uv, st \in E(G)\\
    &&c_{uv, st} &\geqslant a_{u,t} + a_{t,v} + a_{v,s} - 2,&&\forall uv, st \in E(G)\\
    &&c_{uv, st} &\geqslant a_{v,s} + a_{s,u} + a_{u,t} - 2,&&\forall uv, st \in E(G)\\
    &&c_{uv, st} &\geqslant a_{v,t} + a_{t,u} + a_{u,s} - 2,&&\forall uv, st \in E(G)\\
    &&c_{uv, st} &\geqslant a_{s,u} + a_{u,t} + a_{t,v} - 2,&&\forall uv, st \in E(G)\\
    &&c_{uv, st} &\geqslant a_{t,u} + a_{u,s} + a_{s,v} - 2,&&\forall uv, st \in E(G)\\
    &&c_{uv, st} &\geqslant a_{s,v} + a_{v,t} + a_{t,u} - 2,&&\forall uv, st \in E(G)\\
    &&c_{uv, st} &\geqslant a_{t,v} + a_{v,s} + a_{s,u} - 2,&&\forall uv, st \in E(G)\\
    &&a_{u, w} &\geqslant a_{u, v} + a_{v, w} - 1,&&\forall u, v, w \in V(G)\\
    &&c_{uv, st} &\in \{0, 1\},&&\forall uv, st \in E(G)\\
    &&a_{u, v} &\in \{0, 1\},&&\forall u, v \in V(G)\\
\end{align*}

\section{SAT Formulation (unchanged)}\label{sec:SAT-def}

Another approach to solving this problem is to check for a specific $k$ whether the given graph is outer-$k$-planar.
This check can be encoded as a boolean satisfiability problem.
This problem asks whether it is possible to assign logic values $\textsc{True}$ or $\textsc{False}$ so that all disjunctive clauses are satisfied.
A disjunctive clause is a single literal or a disjunction of several.
Literal is either a variable or a negation of a variable, with the former being the positive and the latter the negative literal.


Similarly to the ILP algorithm described in~\ref{sec:ILP-def}, this algorithm uses the same ``ordering variables'' $a_{u, v}$ for each pair of vertices $u$ and $v$ that represent the arrangement of the vertices.
If the boolean variable $a_{u, v}$ is $\textsc{True}$, the vertex $u$ is located before the vertex $v$ and vice versa otherwise.

Similarly, these variables must account for transitivity, which means that for every triple of vertices $u$, $v$, and $w$ $a_{u, v} \equiv \textsc{True}$ and $a_{v, w} \equiv \textsc{True}$ implies $a_{u, w} \equiv \textsc{True}$.
This can be written as follows: $a_{u, v} \land a_{v, w} \rightarrow a_{u, w}$.
Expanding the implication, this transforms into $\overline{a_{u, v} \land a_{v, w}} \lor a_{u, w}$.
After applying De Morgan's law, we receive $\overline{a_{u, v}} \lor \overline{a_{v, w}} \lor a_{u, w}$, which represents a clause in the SAT problem.

The next step is to represent the crossing variables $c_{uv, st}$ in terms of the ordering ones for each pair of edges $uv$ and $st$.
Similarly to the ILP algorithm, we can restrict $c_{uv, st}$ to $\textsc{True}$ if $uv$ and $st$ cross by adding new clauses to the problem.
The clauses are constructed by making the implications for each of the eight intersecting cases shown in figure~\ref{fig:edge_crossings}, expanding them, and applying De Morgan's law.
For example, for the case $a_{u,s} = 1$, $a_{s,v} = 1$, and $a_{v,t} = 1$, we start with the logical equation as follows: $a_{u,s} \land a_{s,v} \land a_{v,t} \rightarrow c_{uv, st}$.
Afterwards, we expand the implication: $\overline{a_{u,s} \land a_{s,v} \land a_{v,t}} \lor c_{uv, st}$.
Finally, we apply De Morgan's law: $\overline{a_{u,s}} \lor \overline{a_{s,v}} \lor \overline{a_{v,t}} \lor c_{uv, st}$ receiving one of the eight clauses for $c_{uv, st}$.

% Help
The last step in the construction of the problem is to count the number of crossings for each edge.
The goal of this solver is to check whether the number of crossings can be smaller or equal to some constant $k$ for each edge.
To ensure this, we can build a set of clauses that prevent the problem from being satisfiable if the value $k$ is too small.
To do so, for every edge $e_0$, we consider all combinations of $e_1, e_2, \dots, e_{k+1}$ for each of which we construct the following clause: $\overline{c_{e_0, e_1}} \lor \overline{c_{e_0, e_2}} \lor \cdots\lor \overline{c_{e_0, e_{k+1}}}$.
Doing so, we ensure that for each edge $e_0$, no $k + 1$ different edges intersect $e_0$, which effectively means that each edge has at most $k$ crossings if all clauses are satisfied.

\todo[inline]{implementation details (iterate over all permutations, finding minimal k)}
\todo[inline]{possible optimizations (2k + 2, equivalence instead of implication for c\_\{...\}, eliminating c\_\{...\} at all)}

\section{Dynamic algorithm}

The last algorithm we considered was introduced by \citeauthor{okp}~\cite{okp}. The main idea of the algorithm is to incrementally build the drawing of the graph. Each step of this process can be mainly parametrized by two parameters: active link and right side. The former is a pair of vertices \(u\) and \(v\) that split a potential drawing in two parts. And latter is a set of vertices, located in the right part of the split. On each step algorithm checks whether such drawing is possible and which arrangements of the edges crossing the link which there are at most \(k\) does it produce.

To do so, the authors used the result of \citeauthor{triangulations}, who showed~\cite{triangulations} that in such configuration in a valid outer \(k\)-planar drawing it is possible to split the right side into two smaller parts by selecting a vertex \(w\) from the right side in such a way that both links \(uw\) and \(vw\) are crossed by at most \(k\) edges. By reversing this argument we get that outer \(k\)-planar drawing for \(uv\) configuration is possible if and only if we can combine it from two valid configurations \(uw\) and \(vw\) for some vertex \(w\) from the right side.

At the end, to get whether the graph is outer \(k\)-planar algorithm checks weather there is a valid drawing for any link with the right side being the whole graph except two vertices of the link. Similar to the SAT formulation~\ref{sec:SAT-def} this method only tests whether the graph admits outer \(k\)-planar drawing or not for a given \(k\), so to find the minimal possible \(k\) we have to incrementally check the values.

In the implementation of the algorithm we firstly construct an index for a dynamic programing table that contained all possible right sides for each link alongside the list of crossing edges grouped by the size of the right part. Since amount of crossing edges is bounded from above by \(k\), the number of entries in this index can be bounded by the following amount:~\(2^{O(k)}m^{k+O(1)}\)~\cite[Lemma 15]{okp}.

To fill the index we start by choosing the number \(l\) of edges that will cross the link\footnote{By iterating over this first, we ensure that it is easy to extend the index for \(k+1\) edges if the check for outer \(k\)-planarity is unsecsessfull.}. Then for each pair of vertices as a link we select exactly \(l\) edges from an augmented graph \(H\) that is obtained from an original graph \(G\) by removing the link vertices. Some connected components of \(H\) are father split by chosen edges on connected subcomponents. Each such subcomponent must be located on one side of the link, as it does not contain edges that cross the link. Thus finding all valid right side for a given link means finding all valid black-white colorings of subcomponents, where white indicates that subcomponent is located on the right side and black~--~on the left side. As a consequence, each selected edge has to connect subcomponents of different color, thus, the metagraph of each connected component of \(H\) with subcomponents as vertices and selected edges connecting them has to be bipartite. After checking that this holds for each metagraph we construct all possible right sides for selected configurations. As each such metagraph can be colored in exactly two ways, there are exactly \(2^d\) possible right sides for selected configurations, where \(d\) is the number of connected components in graph \(H\). As a result, there are might be huge number of entries in the index and consequently the table itself, so to minimise the memory consumption and make it feasible we represent right sides as binary masks stored as 64-bit integers. This decision limits current implementation to graphs with at most 64 vertices, but considering the complexity of the algorithm we believe the graphs of this size would require unreasonable amount of resources anyway\footnote{Potentially it is possible to develop a specified bitmask object which could handle any number of vertices by using multiple integers stored in an array.}.

In the dynamic programing table itself we store discovered arrangements for all right sides of each pair of vertices. Each arrangement contains an order in which edges intersect a link and also number of edges each one of them crossed in the drawing of the right side.

After filling the table index we precede to fill the table itself. We start by iterating over the size of the right side. As on each step we split the right side on two arbitrary parts, all sides with the smaller size should be already processed at any step. For each pair of vertices \(u\) and \(v\) we iterate then over all possible tight sides from the index with the previously selected size. For each such right side \(R_{uv}\) we select a split vertex \(w\), so that \(w \in R_{uv}\). For each \(w\) we iterate over all already considered right sides for a link \(uw\). For each such side \(R_{uw} \subset R_{uv}\) we check whether it and right side for the other link \(R_{vw} = R_{uv} \setminus R_{uw} \setminus \{w\}\) have valid arrangements \(A_{uw}\) and \(A_{vw}\)\footnote{I think I should use another letter}, and for each pair of arrangements we check whether it is possible to combine them.

To check whether two arrangements are consistent, we construct a triangle drawing containing three vertices \(u\), \(v\) and \(w\), and all the edges crossing at least one of the links \(uv\), \(uw\) and \(vw\). Additionally we include edge \((u, v)\) if such exists. Apart from the edges themselves we also need the order in which they appear in the triangle. The order in which edges cross the links \(uw\) and \(vw\) come from arrangements \(A_{uw}\) and \(A_{vw}\) respectively, and the order in which edges cross the link \(uv\) are looked through one by one. Given that \(l_{uv}\) edges cross \(uv\) we introduce

